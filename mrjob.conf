runners:
    local:
        cleanup: NONE
    hadoop: # this will work for both hadoop and emr
    emr:
        jobconf:
            # Configure hadoop to compress its final (and intermediary) output.
            # This will yield savings both for writing, reading and during
            # MR processing.
            # Notice: "true" must be a string argument, not a boolean! (#323)
            mapred.output.compress: "true"
            mapred.output.compression.codec: org.apache.hadoop.io.compress.GzipCodec
            mapred.compress.map.output: "true"
        cleanup: ALL
        ami_version: latest
        aws_region: us-east-1
        # Security credentials:
        aws_access_key_id: AKIAIJAFPDUUGJFCLCBA
        #aws_secret_access_key: <KEY HERE>
        #ec2_key_pair: your_key_here
        s3_log_uri: s3://ufcgplayground/log/
        s3_scratch_uri: s3://ufcgplayground/tmp/
        # use beefier instances in production
        ec2_master_instance_type: m1.small
        ec2_core_instance_type: m1.small
        num_ec2_instances: 11
        ec2_core_instance_bid_price: '0.10'
        bootstrap_actions:
        - s3://elasticmapreduce/bootstrap-actions/configurations/latest/memory-intensive
        #bootstrap_cmds:
        #- sudo apt-get install -y python-simplejson
        #python_archives:
        #- extra_code.tar.gz